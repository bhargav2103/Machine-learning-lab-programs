import numpy as np
from sklearn import preprocessing,cross_validation,neighbors
import pandas as pd
import matplotlib.pyplot as plt

#dataset=[[1,4,1],[2,4.5,1],[5,2,2],[2,'?',1],[3,6,1],[6,3,2],[5,2,2],[5,1,2],[3,6,1],[6,3,2]]

#labels=['height','paw','class']

#df=pd.DataFrame(dataset,columns=labels)

df = pd.read_csv("iris.csv")

df.replace('setosa',1,inplace=True)
df.replace('versicolor',2,inplace=True)
df.replace('virginica',3,inplace=True)

#handling missing data
df.replace('?',-9999,inplace=True)


#define attributes and classes
X=np.array(df.drop(['species'],1))
Y=np.array(df['species'])

X_train,X_test,Y_train,Y_test= cross_validation.train_test_split(X,Y,test_size=0.2)

plt.plot(X_train,Y_train)
# Define the classifier using panda library

clf=neighbors.KNeighborsClassifier()

# Save the model with the fit method
clf.fit(X_train,Y_train)

# use the test set and calculate the accuracy of the model
accuracy=clf.score(X_test, Y_test)

print("Accuracy:")
print(accuracy)

example_measures = np.array([6.2,2.9,5.6,1.8])
example_measures = example_measures.reshape(1,-1)

prediction = clf.predict(example_measures)

print(prediction)
