{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.preprocessing import Imputer, StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class Predict:\n",
    "    def __init__(self):\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "\n",
    "    def Read_Clean(self,dataset):\n",
    "        header_row = ['Age', 'Gender', 'Chest_Pain', 'Resting_Blood_Pressure', 'Serum_Cholestrol',\n",
    "                      'Fasting_Blood_Sugar', 'Resting_ECG', 'Max_Heart_Rate',\n",
    "                      'Exercise_Induced_Angina', 'OldPeak',\n",
    "                      'Slope', 'CA', 'Thal', 'Num']\n",
    "        df = pd.read_csv(dataset, names=header_row)\n",
    "        df = df.replace('[?]', np.nan, regex=True)\n",
    "        df = pd.DataFrame(Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "                          .fit_transform(df), columns=header_row)\n",
    "        df = df.astype(float)\n",
    "        return df\n",
    "\n",
    "    def Split_Dataset(self, df):\n",
    "        self.Y = df['Num'].apply(lambda x: 1 if x > 0 else 0)\n",
    "        self.X = df.drop('Num', axis=1)\n",
    "\n",
    "    def Create_Pipeline(self):\n",
    "        estimators = []\n",
    "        estimators.append(('standardize', StandardScaler()))\n",
    "        estimators.append(('bayes', GaussianNB()))\n",
    "        model = Pipeline(estimators)\n",
    "        return model\n",
    "\n",
    "    def Cross_Validate(self, clf, cv=5):\n",
    "        scores = cross_val_score(clf, self.X, self.Y, cv=cv, scoring='f1')\n",
    "        score = scores.mean()\n",
    "        print(\"CV scores mean: %.4f \" % (score))\n",
    "\n",
    "    def Fit_Score(self, clf, label='x'):\n",
    "        clf.fit(self.X, self.Y)\n",
    "        fit_score = clf.score(self.X, self.Y)\n",
    "        print(\"%s: fit score %.5f\" % (label, fit_score))\n",
    "\n",
    "    def ReturnPredictionValue(self, clf, sample):\n",
    "        y = clf.predict([sample])\n",
    "        return y[0]\n",
    "\n",
    "\n",
    "    def PredictionMain(self, sample, dataset_path='processed.cleveland.data'):\n",
    "        print(\"HDdata: \"+ dataset_path)\n",
    "        data = self.Read_Clean(dataset_path)\n",
    "        self.Split_Dataset(data)\n",
    "        self.model = self.Create_Pipeline()\n",
    "        self.Fit_Score(self.model, label='NB')\n",
    "        self.Cross_Validate(self.model, 10)\n",
    "        return self.ReturnPredictionValue(self.model, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CheckTrue(self):\n",
    "    clf = self.Create_Pipeline()\n",
    "    out = cross_val_predict(clf, self.X, self.Y)\n",
    "    p = [out == self.Y]\n",
    "    c = 0\n",
    "    for i in range(303):\n",
    "        if p[0][i] == True:\n",
    "            c += 1\n",
    "    print(\"Samples with true values: {}\".format(c))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-04263c935178>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-e740e822d71b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset_path' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
